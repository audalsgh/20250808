{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/audalsgh/20250808/blob/main/day5_lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "그냥 Numpy가 아니라, 코랩에서 cuda를 사용하기 위한 \"Numba-cuda\"를 설치할것."
      ],
      "metadata": {
        "id": "zuDelkhtF-Gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## See: https://github.com/googlecolab/colabtools/issues/5081#issuecomment-2629611179\n",
        "!uv pip install -q --system numba-cuda==0.4.0\n",
        "from numba import config\n",
        "config.CUDA_ENABLE_PYNVJITLINK = 1\n",
        "config.CUDA_LOW_OCCUPANCY_WARNINGS = 0"
      ],
      "metadata": {
        "id": "tz71474MjSdp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['NUMBA_CUDA_ARCH'] = 'sm_75'"
      ],
      "metadata": {
        "id": "QWpgC_Uffx1K"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numba\n",
        "import numpy as np\n",
        "from numba import vectorize, jit, cuda\n",
        "print(\"Numpy version: \", np.__version__)\n",
        "print(\"numba version: \", numba.__version__)\n",
        "print(\"Cuda avilable\") if cuda.detect() else print(\"Cuda not avilable\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUyOZ52IguFr",
        "outputId": "8f578260-4075-43d5-8839-29a5f88cb135"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numpy version:  2.0.2\n",
            "numba version:  0.60.0\n",
            "Found 1 CUDA devices\n",
            "id 0             b'Tesla T4'                              [SUPPORTED]\n",
            "                      Compute Capability: 7.5\n",
            "                           PCI Device ID: 4\n",
            "                              PCI Bus ID: 0\n",
            "                                    UUID: GPU-5ba2b968-5b93-7fe6-f092-ba532cd3cd3e\n",
            "                                Watchdog: Disabled\n",
            "             FP32/FP64 Performance Ratio: 32\n",
            "Summary:\n",
            "\t1/1 devices are supported\n",
            "Cuda avilable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF4bnT54ecQt"
      },
      "source": [
        "# Day 5: CUDA 파이썬을 이용한 자율주행 데이터 가속\n",
        "\n",
        "**과정 목표:** 지난 4일간 배운 자율주행 데이터 처리 알고리즘들을 GPU를 이용해 가속하는 방법을 배웁니다. Numba 라이브러리를 사용하여 Python으로 직접 CUDA 코드를 작성하고, 병렬 처리의 핵심 원리와 최적화 기법을 실습을 통해 익힙니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nc5JvuhDecQv"
      },
      "source": [
        "---\n",
        "## Lab 1: Numba Ufunc, 프로파일링, 그리고 정밀도\n",
        "\n",
        "**실습 목표:**\n",
        "1. 간단한 이미지 처리 작업을 위한 GPU 범용 함수(ufunc)를 작성합니다.\n",
        "2. 데이터 크기에 따른 CPU와 GPU의 성능을 `%%timeit`으로 비교하여 메모리 전송 오버헤드를 확인합니다.\n",
        "3. `float32`와 `float64`의 정밀도 차이가 계산 결과에 미치는 영향을 직접 확인합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaYwbegaecQw"
      },
      "source": [
        "### 준비: 라이브러리 임포트 및 데이터 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnZDPvD0ecQw",
        "outputId": "ba564a7a-0ed4-437e-9b00-b7a1318718eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "생성된 이미지 크기: 1365x768 (1.00 MB)\n",
            "생성된 이미지 크기: 13653x7680 (100.00 MB)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numba import vectorize, jit\n",
        "import time\n",
        "\n",
        "# 자율주행 카메라 이미지를 모방한 가상 데이터 생성\n",
        "def create_image(size_mb):\n",
        "    # 1 pixel = 1 byte (uint8)\n",
        "    num_pixels = size_mb * 1024 * 1024\n",
        "    # 이미지의 가로:세로 비율을 16:9로 가정\n",
        "    height = int(np.sqrt(num_pixels * 9 / 16))\n",
        "    width = int(height * 16 / 9)\n",
        "    print(f\"생성된 이미지 크기: {width}x{height} ({width*height/1024/1024:.2f} MB)\")\n",
        "    return np.random.randint(0, 256, size=(height, width), dtype=np.uint8)\n",
        "\n",
        "small_image = create_image(1)    # 약 1MB 크기 이미지\n",
        "large_image = create_image(100)  # 약 100MB 크기 이미지"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmjuAVICecQx"
      },
      "source": [
        "### 파트 1: 성능 비교 - 이미지 임계값 처리\n",
        "\n",
        "이미지에서 특정 밝기 값(임계값)보다 밝은 픽셀은 흰색(255)으로, 어두운 픽셀은 검은색(0)으로 만드는 것은 객체 감지의 가장 기본적인 전처리 단계입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uG0uR-hmecQx"
      },
      "outputs": [],
      "source": [
        "# TODO: 아래 함수를 Numba의 @vectorize 데코레이터를 사용하여 GPU ufunc으로 변환하세요.\n",
        "# target을 'cuda'로 설정하는 것을 잊지 마세요.\n",
        "# 타입 시그니처: uint8를 입력받아 uint8를 반환 -> ['uint8(uint8, uint8)']\n",
        "\n",
        "from numba import vectorize, uint8, cuda\n",
        "\n",
        "@vectorize([uint8(uint8, uint8)], target='cuda')\n",
        "def gpu_threshold(pixel, threshold):\n",
        "    return 255 if pixel > threshold else 0\n",
        "\n",
        "# CPU 버전 (NumPy)\n",
        "def cpu_threshold_numpy(image, threshold):\n",
        "    return np.where(image > threshold, 255, 0).astype(np.uint8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkWiUIBoecQx"
      },
      "source": [
        "#### 작은 이미지 성능 측정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRV4I80kecQx",
        "outputId": "2a49a343-3a71-4663-b1a8-c4be82b1c6af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 작은 이미지 (1MB) 성능 비교 ---\n",
            "CPU (NumPy):\n",
            "6.12 ms ± 58.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "\n",
            "GPU (Numba ufunc):\n",
            "2.15 ms ± 41.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ],
      "source": [
        "print(\"--- 작은 이미지 (1MB) 성능 비교 ---\")\n",
        "print(\"CPU (NumPy):\")\n",
        "%timeit cpu_threshold_numpy(small_image, 128)\n",
        "\n",
        "print(\"\\nGPU (Numba ufunc):\")\n",
        "# 첫 실행은 컴파일 시간 포함\n",
        "_ = gpu_threshold(small_image, 128)\n",
        "%timeit gpu_threshold(small_image, 128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tV83_KvdecQx"
      },
      "source": [
        "#### 큰 이미지 성능 측정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iiHbigJecQx",
        "outputId": "b953d453-5bce-4d50-9382-171c03e38e90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 큰 이미지 (100MB) 성능 비교 ---\n",
            "CPU (NumPy):\n",
            "883 ms ± 68 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
            "\n",
            "GPU (Numba ufunc):\n",
            "125 ms ± 14.5 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "print(\"--- 큰 이미지 (100MB) 성능 비교 ---\")\n",
        "print(\"CPU (NumPy):\")\n",
        "%timeit cpu_threshold_numpy(large_image, 128)\n",
        "\n",
        "print(\"\\nGPU (Numba ufunc):\")\n",
        "_ = gpu_threshold(large_image, 128)\n",
        "%timeit gpu_threshold(large_image, 128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pJcR3cWecQx"
      },
      "source": [
        "#### 분석 질문\n",
        "1. 작은 이미지와 큰 이미지에서 CPU와 GPU의 성능 차이는 어떻게 나타났나요?\n",
        "2. 왜 이런 차이가 발생했을까요? 강의에서 배운 '메모리 전송 오버헤드' 개념과 연관지어 설명해보세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYpjGbSkecQx"
      },
      "source": [
        "### 파트 2: 정밀도 문제 (Nefarious Example)\n",
        "\n",
        "강의에서 본 '치명적 상쇄(Catastrophic Cancellation)' 문제를 직접 확인해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numba import vectorize\n",
        "\n",
        "# Corrected version to demonstrate precision loss\n",
        "@vectorize(['float32(float32)'], target='cuda')\n",
        "def precision_test_f32_corrected(x):\n",
        "    # Force the literal '1.0' to be a 32-bit float\n",
        "    one_f32 = np.float32(1.0)\n",
        "    return (one_f32 + x) - one_f32\n",
        "\n",
        "@vectorize(['float64(float64)'], target='cuda')\n",
        "def precision_test_f64(x):\n",
        "    # For float64, using a Python literal is fine as it's already 64-bit\n",
        "    return (1.0 + x) - 1.0\n",
        "\n",
        "# Using a value that WILL be lost in float32 but not float64\n",
        "# float32 machine epsilon is ~1.19e-7. 1e-8 is smaller than that.\n",
        "val = 1e-8\n",
        "x_f32 = np.array([val], dtype=np.float32)\n",
        "x_f64 = np.array([val], dtype=np.float64)\n",
        "\n",
        "# Run the corrected f32 version and the f64 version\n",
        "result_f32 = precision_test_f32_corrected(x_f32)\n",
        "result_f64 = precision_test_f64(x_f64)\n",
        "\n",
        "print(f\"입력 값: {val}\")\n",
        "print(f\"Corrected Float32 결과: {result_f32[0]}\")\n",
        "print(f\"Float64 결과: {result_f64[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0g4TVqsal6kz",
        "outputId": "7cb51211-2911-4048-e4e5-667f9811ee78"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 값: 1e-08\n",
            "Corrected Float32 결과: 0.0\n",
            "Float64 결과: 9.99999993922529e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wb0TjWr5ecQy"
      },
      "source": [
        "#### 분석 질문\n",
        "1. `float32`와 `float64`의 결과가 왜 다르게 나왔나요?\n",
        "2. 만약 Day 1의 칼만 필터나 Day 4의 PID 제어기처럼 정밀한 계산이 필요한 알고리즘을 GPU로 가속한다면, 이 결과가 어떤 중요한 점을 시사할까요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMd5XsT7ecQy"
      },
      "source": [
        "---\n",
        "## Lab 2: 커스텀 커널과 메모리 Coalescing\n",
        "Numpy 배열은 행 우선(row-major) 방식, 행 방향인 가로로 \"연속적인 메모리 주소\"를 갖기에,<br>행 방향으로 한번의 트랜잭션을 하여, 32개의 주소 요청을 처리하는게 좋음\n",
        "\n",
        "**실습 목표:**\n",
        "1. 2D 이미지(행렬) 처리를 위한 커스텀 CUDA 커널을 작성합니다.\n",
        "2. 메모리 접근 패턴(Coalesced vs. Uncoalesced)이 성능에 미치는 극적인 영향을 `%%timeit`과 프로파일러로 직접 확인하고 분석합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3dnJhFmecQy"
      },
      "source": [
        "### 준비: 라이브러리 임포트 및 데이터 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "j-_U9UVHecQy"
      },
      "outputs": [],
      "source": [
        "from numba import cuda\n",
        "\n",
        "# 2048x2048 크기의 가상 행렬 데이터 생성\n",
        "N = 2048\n",
        "matrix = np.arange(N * N, dtype=np.float32).reshape(N, N)\n",
        "\n",
        "# GPU로 데이터 전송\n",
        "d_matrix = cuda.to_device(matrix)\n",
        "d_transposed = cuda.device_array_like(d_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLTg3QNuecQy"
      },
      "source": [
        "### 파트 1: 행렬 전치(Transpose) 커널 작성\n",
        "\n",
        "행렬 전치는 메모리 접근 패턴의 중요성을 보여주는 고전적인 예제입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4dVBm9QUecQy"
      },
      "outputs": [],
      "source": [
        "@cuda.jit\n",
        "def transpose_uncoalesced_kernel(A, B):\n",
        "    # 2D 그리드에서 스레드의 x, y 좌표를 얻습니다.\n",
        "    x, y = cuda.grid(2)\n",
        "\n",
        "    # 경계 검사\n",
        "    if x < B.shape[0] and y < B.shape[1]:\n",
        "        # TODO: Uncoalesced 접근을 유발하는 코드를 작성하세요.\n",
        "        # 힌트: 인접 스레드(x가 1씩 변함)가 메모리 상에서 멀리 떨어진 위치에 쓰도록 만드세요.\n",
        "        # B[y, x] = A[x, y] 와 같은 형태가 될 것입니다.\n",
        "        B[y, x] = A[x, y]\n",
        "\n",
        "@cuda.jit\n",
        "def transpose_coalesced_kernel(A, B):\n",
        "    x, y = cuda.grid(2)\n",
        "\n",
        "    if x < B.shape[0] and y < B.shape[1]:\n",
        "        # TODO: Coalesced 접근이 일어나도록 코드를 작성하세요.\n",
        "        # 힌트: 인접 스레드가 메모리 상에서 연속된 위치에 쓰도록 만드세요.\n",
        "        # B[x, y] = A[y, x] 와 같은 형태가 될 것입니다.\n",
        "\n",
        "        # A행렬의 열 순서를 가로축으로 보고, B행렬의 행을 채웠다.\n",
        "        # 출력되는 B행렬은 가로방향으로 진행하는 메모리 병합 접근 방식!\n",
        "        B[x, y] = A[y, x]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-g9k-14ecQy"
      },
      "source": [
        "### 파트 2: 성능 측정 및 프로파일링\n",
        "\n",
        "두 커널의 실행 시간을 측정하고 비교해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJwgAPDmecQy",
        "outputId": "cf8f141f-6659-4b50-9535-6d6c56121529"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Uncoalesced Kernel 성능 ---\n",
            "219 µs ± 915 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
            "\n",
            "--- Coalesced Kernel 성능 ---\n",
            "73.9 µs ± 39.4 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "# 실행 구성 설정\n",
        "threads_per_block = (32, 32)\n",
        "blocks_per_grid_x = int(np.ceil(matrix.shape[0] / threads_per_block[0]))\n",
        "blocks_per_grid_y = int(np.ceil(matrix.shape[1] / threads_per_block[1]))\n",
        "blocks_per_grid = (blocks_per_grid_x, blocks_per_grid_y)\n",
        "\n",
        "print(\"--- Uncoalesced Kernel 성능 ---\")\n",
        "%timeit transpose_uncoalesced_kernel[blocks_per_grid, threads_per_block](d_matrix, d_transposed)\n",
        "\n",
        "print(\"\\n--- Coalesced Kernel 성능 ---\")\n",
        "%timeit transpose_coalesced_kernel[blocks_per_grid, threads_per_block](d_matrix, d_transposed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Mjko857ecQz"
      },
      "source": [
        "#### (선택) 프로파일러로 확인하기\n",
        "\n",
        "만약 로컬 환경에 CUDA Toolkit이 설치되어 있다면, 위 커널들을 별도의 `.py` 파일로 저장한 뒤 터미널에서 아래 명령어를 실행하여 메모리 처리량을 직접 확인할 수 있습니다.\n",
        "\n",
        "`$ nsys profile python your_script.py`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqS2SailecQz"
      },
      "source": [
        "#### 분석 질문\n",
        "1. 두 커널의 성능 차이가 얼마나 컸나요?\n",
        "2. 왜 이런 차이가 발생했는지 '메모리 병합(Coalescing)'과 '행 우선 저장(Row-major Layout)' 개념을 사용하여 설명하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOCW_nRnecQz"
      },
      "source": [
        "---\n",
        "## Lab 3: 원자적 연산과 경쟁 상태\n",
        "\n",
        "**실습 목표:**\n",
        "1. 여러 스레드가 공유 자원에 동시에 접근할 때 발생하는 경쟁 상태(Race Condition) 문제를 직접 재현합니다.\n",
        "2. 원자적 연산(Atomic Operation)을 사용하여 이 문제를 해결하고, 병렬 알고리즘의 정확성을 보장하는 방법을 익힙니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4FE8mlaecQz"
      },
      "source": [
        "### 준비: 데이터 생성\n",
        "\n",
        "이미지의 밝기 값 분포를 나타내는 히스토그램을 계산하는 상황을 가정합니다. 히스토그램은 0부터 255까지 256개의 빈(bin)을 가집니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MdkHbqB4ecQz"
      },
      "outputs": [],
      "source": [
        "# 100만 픽셀을 가진 가상 이미지 데이터 (밝기 값만 1D 배열로)\n",
        "num_pixels = 1_000_000\n",
        "image_pixels = np.random.randint(0, 256, size=num_pixels, dtype=np.int32)\n",
        "\n",
        "# GPU로 데이터 전송\n",
        "d_image_pixels = cuda.to_device(image_pixels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfJwwLCdecQz"
      },
      "source": [
        "### 파트 1: 경쟁 상태 재현하기 (잘못된 커널)\n",
        "\n",
        "먼저, 원자적 연산을 사용하지 않고 히스토그램을 계산하는 커널을 작성해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPErLbpHecQz",
        "outputId": "fd00fe32-c18e-457e-995f-51a1634ac0c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "경쟁 상태 커널 결과 (총합): 17208\n",
            "실제 픽셀 수: 1000000\n",
            "결과가 정확한가? False\n"
          ]
        }
      ],
      "source": [
        "@cuda.jit\n",
        "def histogram_race_condition_kernel(pixels, hist_out):\n",
        "    # 그리드-스트라이드 루프를 사용하여 모든 픽셀을 처리할 예정.\n",
        "    start = cuda.grid(1)\n",
        "    stride = cuda.gridsize(1)\n",
        "\n",
        "    for i in range(start, pixels.shape[0], stride):\n",
        "        pixel_value = pixels[i]\n",
        "        # TODO: 경쟁 상태를 유발하는 코드를 작성하세요.\n",
        "        # 단순히 해당 빈의 값을 1 증가시키는 코드임.\n",
        "        hist_out[pixel_value] += 1\n",
        "\n",
        "# 히스토그램 배열 초기화 및 실행\n",
        "d_hist_1 = cuda.to_device(np.zeros(256, dtype=np.int32))\n",
        "histogram_race_condition_kernel[256, 256](d_image_pixels, d_hist_1)\n",
        "\n",
        "# 결과 확인\n",
        "hist_1_result = d_hist_1.copy_to_host()\n",
        "print(f\"경쟁 상태 커널 결과 (픽셀 총합): {hist_1_result.sum()}\")\n",
        "print(f\"실제 픽셀 수: {num_pixels}\")\n",
        "print(f\"결과가 정확한가? {hist_1_result.sum() == num_pixels}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLB3HpxVecQz"
      },
      "source": [
        "### 파트 2: 원자적 연산으로 문제 해결하기\n",
        "\n",
        "이제 `cuda.atomic.add`를 사용하여 경쟁 상태를 해결해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbpWUrqFecQz",
        "outputId": "419e472c-64fc-4837-9b46-50d9b5ecdd0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원자적 연산 커널 결과 (총합): 1000000\n",
            "실제 픽셀 수: 1000000\n",
            "결과가 정확한가? True\n"
          ]
        }
      ],
      "source": [
        "@cuda.jit\n",
        "def histogram_atomic_kernel(pixels, hist_out):\n",
        "    start = cuda.grid(1)\n",
        "    stride = cuda.gridsize(1)\n",
        "\n",
        "    for i in range(start, pixels.shape[0], stride):\n",
        "        pixel_value = pixels[i]\n",
        "        # TODO: cuda.atomic.add를 사용하여 안전하게 빈의 값을 1 증가시키세요.\n",
        "        # 사용법: cuda.atomic.add(배열, 인덱스, 증가값)\n",
        "        cuda.atomic.add(hist_out, pixel_value, 1)\n",
        "\n",
        "# 히스토그램 배열 초기화 및 실행\n",
        "d_hist_2 = cuda.to_device(np.zeros(256, dtype=np.int32))\n",
        "histogram_atomic_kernel[256, 256](d_image_pixels, d_hist_2)\n",
        "\n",
        "# 결과 확인\n",
        "hist_2_result = d_hist_2.copy_to_host()\n",
        "print(f\"원자적 연산 커널 결과 (총합): {hist_2_result.sum()}\")\n",
        "print(f\"실제 픽셀 수: {num_pixels}\")\n",
        "print(f\"결과가 정확한가? {hist_2_result.sum() == num_pixels}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eefQRqL6ecQz"
      },
      "source": [
        "#### 분석 질문\n",
        "1. 첫 번째 커널의 결과가 왜 부정확했나요? '읽기-수정-쓰기' 사이클과 연관지어 구체적인 시나리오를 설명해보세요.\n",
        "2. `cuda.atomic.add`는 이 문제를 어떻게 해결했나요?\n",
        "3. 자율주행 시스템에서 여러 센서 데이터를 종합하여 하나의 지도(Occupancy Grid Map)를 업데이트하는 상황을 상상해보세요.<br>이 상황에서 원자적 연산이 왜 중요할까요?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}